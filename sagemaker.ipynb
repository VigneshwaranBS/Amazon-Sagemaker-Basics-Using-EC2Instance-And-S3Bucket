{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing  Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps To Be Followed\n",
    "1. Importing necessary Libraries\n",
    "2. Creating S3 bucket \n",
    "3. Mapping train And Test Data in S3\n",
    "4. Mapping The path of the models in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri \n",
    "from sagemaker.session import s3_input, Session\n",
    "from sagemaker import image_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap-south-1\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'banking-app-demo' \n",
    "my_region = boto3.session.Session().region_name \n",
    "print(my_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 error:  An error occurred (IllegalLocationConstraintException) when calling the CreateBucket operation: The unspecified location constraint is incompatible for the region specific endpoint this request was sent to.\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    if  my_region == 'ap-south-1':\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ',e)\n",
    "    \n",
    "    \n",
    "# If it doesn't work create a bucket manually in s3 bucket    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://banking-app-demo/xgboost-as-a-built-in-algo/output\n"
     ]
    }
   ],
   "source": [
    "# set an output path where the trained model will be saved\n",
    "prefix = 'xgboost-as-a-built-in-algo'\n",
    "output_path ='s3://{}/{}/output'.format(bucket_name, prefix)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading The Dataset And Storing in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: downloaded bank_clean.csv.\n",
      "Success: Data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "try:\n",
    "    urllib.request.urlretrieve (\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", \"bank_clean.csv\")\n",
    "    print('Success: downloaded bank_clean.csv.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)\n",
    "\n",
    "try:\n",
    "    model_data = pd.read_csv('./bank_clean.csv',index_col=0)\n",
    "    print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28831, 61) (12357, 61)\n"
     ]
    }
   ],
   "source": [
    "### Train Test split\n",
    "\n",
    "import numpy as np\n",
    "train_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.155.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.173.0.tar.gz (854 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m854.4/854.4 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting attrs<24,>=23.1.0 (from sagemaker)\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.26.144)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.22.3)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (3.20.3)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.0.1)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Collecting PyYAML~=6.0 (from sagemaker)\n",
      "  Using cached PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (3.2.0)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (3.5.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.144 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.29.144)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.15.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.19.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (67.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.144->boto3<2.0,>=1.26.131->sagemaker) (1.26.8)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.173.0-py2.py3-none-any.whl size=1163282 sha256=f1a5a87086f8e6698a5adf13a6be35e617d2ada8c60b3e236e5228f3a5bed1da\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/cc/23/21/6857de3905209ac2dbbe974e18a5654d28cd247f4223ff6bff\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: PyYAML, attrs, sagemaker\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 22.2.0\n",
      "    Uninstalling attrs-22.2.0:\n",
      "      Successfully uninstalled attrs-22.2.0\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.155.0\n",
      "    Uninstalling sagemaker-2.155.0:\n",
      "      Successfully uninstalled sagemaker-2.155.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.144 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "docker-compose 1.29.2 requires PyYAML<6,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "jupyterlab-server 2.22.1 requires jsonschema>=4.17.3, but you have jsonschema 3.2.0 which is incompatible.\n",
      "sparkmagic 0.20.5 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.6 which is incompatible.\n",
      "sparkmagic 0.20.5 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-6.0 attrs-23.1.0 sagemaker-2.173.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "### Saving Train And Test Into Buckets\n",
    "## We start with Train Data\n",
    "import os\n",
    "pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], \n",
    "                                                axis=1)], \n",
    "                                                axis=1).to_csv('train.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = sagemaker.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "# Test Data Into Buckets\n",
    "pd.concat([test_data['y_yes'], test_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('test.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')\n",
    "s3_input_test = sagemaker.TrainingInput(s3_data='s3://{}/{}/test'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Models Xgboot- Inbuilt Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "# container = ImageURIProvider(boto3.Session().region_name,\n",
    "#                           'xgboost', \n",
    "#                           repo_version='1.0-1')\n",
    "\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"1.7-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":50\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:train_max_run has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:train_use_spot_instances has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:train_max_wait has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:train_volume_size has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.m5.2xlarge', \n",
    "                                          train_volume_size=5, # 5 GB \n",
    "                                          output_path=output_path,\n",
    "                                          train_use_spot_instances=True,\n",
    "                                          train_max_run=300,\n",
    "                                          train_max_wait=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2023-07-17-14-55-27-085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-17 14:55:27 Starting - Starting the training job...\n",
      "2023-07-17 14:55:42 Starting - Preparing the instances for training.........\n",
      "2023-07-17 14:57:24 Downloading - Downloading input data\n",
      "2023-07-17 14:57:24 Training - Downloading the training image...\n",
      "2023-07-17 14:57:55 Training - Training image download completed. Training in progress....\n",
      "2023-07-17 14:58:25 Uploading - Uploading generated training model\u001b[34m[2023-07-17 14:58:19.129 ip-10-0-72-225.ap-south-1.compute.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-07-17 14:58:19.152 ip-10-0-72-225.ap-south-1.compute.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-07-17:14:58:19:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2023-07-17:14:58:19:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2023-07-17:14:58:19:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2023-07-17:14:58:19:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2023-07-17:14:58:19:INFO] Determined 0 GPU(s) available on the instance.\u001b[0m\n",
      "\u001b[34m[2023-07-17:14:58:19:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2023-07-17:14:58:19:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2023-07-17:14:58:19:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2023-07-17:14:58:19:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2023-07-17:14:58:19:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[2023-07-17:14:58:19:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2023-07-17:14:58:19:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2023-07-17:14:58:19:INFO] Train matrix has 28831 rows and 59 columns\u001b[0m\n",
      "\u001b[34m[2023-07-17:14:58:19:INFO] Validation matrix has 12357 rows\u001b[0m\n",
      "\u001b[34m[2023-07-17 14:58:19.654 ip-10-0-72-225.ap-south-1.compute.internal:7 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-07-17 14:58:19.655 ip-10-0-72-225.ap-south-1.compute.internal:7 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-07-17 14:58:19.656 ip-10-0-72-225.ap-south-1.compute.internal:7 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-07-17 14:58:19.656 ip-10-0-72-225.ap-south-1.compute.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2023-07-17:14:58:19:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[0]#011train-logloss:0.57287#011validation-logloss:0.57388\u001b[0m\n",
      "\u001b[34m[2023-07-17 14:58:19.749 ip-10-0-72-225.ap-south-1.compute.internal:7 INFO hook.py:427] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2023-07-17 14:58:19.754 ip-10-0-72-225.ap-south-1.compute.internal:7 INFO hook.py:491] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[1]#011train-logloss:0.49295#011validation-logloss:0.49483\u001b[0m\n",
      "\u001b[34m[2]#011train-logloss:0.43699#011validation-logloss:0.44017\u001b[0m\n",
      "\u001b[34m[3]#011train-logloss:0.39663#011validation-logloss:0.40048\u001b[0m\n",
      "\u001b[34m[4]#011train-logloss:0.36733#011validation-logloss:0.37209\u001b[0m\n",
      "\u001b[34m[5]#011train-logloss:0.34574#011validation-logloss:0.35146\u001b[0m\n",
      "\u001b[34m[6]#011train-logloss:0.32987#011validation-logloss:0.33640\u001b[0m\n",
      "\u001b[34m[7]#011train-logloss:0.31788#011validation-logloss:0.32478\u001b[0m\n",
      "\u001b[34m[8]#011train-logloss:0.30914#011validation-logloss:0.31662\u001b[0m\n",
      "\u001b[34m[9]#011train-logloss:0.30226#011validation-logloss:0.31044\u001b[0m\n",
      "\u001b[34m[10]#011train-logloss:0.29718#011validation-logloss:0.30609\u001b[0m\n",
      "\u001b[34m[11]#011train-logloss:0.29317#011validation-logloss:0.30271\u001b[0m\n",
      "\u001b[34m[12]#011train-logloss:0.29028#011validation-logloss:0.30029\u001b[0m\n",
      "\u001b[34m[13]#011train-logloss:0.28766#011validation-logloss:0.29825\u001b[0m\n",
      "\u001b[34m[14]#011train-logloss:0.28567#011validation-logloss:0.29661\u001b[0m\n",
      "\u001b[34m[15]#011train-logloss:0.28434#011validation-logloss:0.29565\u001b[0m\n",
      "\u001b[34m[16]#011train-logloss:0.28328#011validation-logloss:0.29466\u001b[0m\n",
      "\u001b[34m[17]#011train-logloss:0.28189#011validation-logloss:0.29366\u001b[0m\n",
      "\u001b[34m[18]#011train-logloss:0.28103#011validation-logloss:0.29344\u001b[0m\n",
      "\u001b[34m[19]#011train-logloss:0.28020#011validation-logloss:0.29296\u001b[0m\n",
      "\u001b[34m[20]#011train-logloss:0.27964#011validation-logloss:0.29269\u001b[0m\n",
      "\u001b[34m[21]#011train-logloss:0.27923#011validation-logloss:0.29267\u001b[0m\n",
      "\u001b[34m[22]#011train-logloss:0.27900#011validation-logloss:0.29281\u001b[0m\n",
      "\u001b[34m[23]#011train-logloss:0.27840#011validation-logloss:0.29243\u001b[0m\n",
      "\u001b[34m[24]#011train-logloss:0.27799#011validation-logloss:0.29234\u001b[0m\n",
      "\u001b[34m[25]#011train-logloss:0.27755#011validation-logloss:0.29206\u001b[0m\n",
      "\u001b[34m[26]#011train-logloss:0.27718#011validation-logloss:0.29196\u001b[0m\n",
      "\u001b[34m[27]#011train-logloss:0.27688#011validation-logloss:0.29192\u001b[0m\n",
      "\u001b[34m[28]#011train-logloss:0.27663#011validation-logloss:0.29183\u001b[0m\n",
      "\u001b[34m[29]#011train-logloss:0.27642#011validation-logloss:0.29160\u001b[0m\n",
      "\u001b[34m[30]#011train-logloss:0.27613#011validation-logloss:0.29140\u001b[0m\n",
      "\u001b[34m[31]#011train-logloss:0.27585#011validation-logloss:0.29134\u001b[0m\n",
      "\u001b[34m[32]#011train-logloss:0.27554#011validation-logloss:0.29137\u001b[0m\n",
      "\u001b[34m[33]#011train-logloss:0.27516#011validation-logloss:0.29135\u001b[0m\n",
      "\u001b[34m[34]#011train-logloss:0.27511#011validation-logloss:0.29132\u001b[0m\n",
      "\u001b[34m[35]#011train-logloss:0.27494#011validation-logloss:0.29133\u001b[0m\n",
      "\u001b[34m[36]#011train-logloss:0.27468#011validation-logloss:0.29143\u001b[0m\n",
      "\u001b[34m[37]#011train-logloss:0.27429#011validation-logloss:0.29122\u001b[0m\n",
      "\u001b[34m[38]#011train-logloss:0.27401#011validation-logloss:0.29117\u001b[0m\n",
      "\u001b[34m[39]#011train-logloss:0.27385#011validation-logloss:0.29128\u001b[0m\n",
      "\u001b[34m[40]#011train-logloss:0.27366#011validation-logloss:0.29118\u001b[0m\n",
      "\u001b[34m[41]#011train-logloss:0.27351#011validation-logloss:0.29117\u001b[0m\n",
      "\u001b[34m[42]#011train-logloss:0.27316#011validation-logloss:0.29111\u001b[0m\n",
      "\u001b[34m[43]#011train-logloss:0.27294#011validation-logloss:0.29095\u001b[0m\n",
      "\u001b[34m[44]#011train-logloss:0.27274#011validation-logloss:0.29101\u001b[0m\n",
      "\u001b[34m[45]#011train-logloss:0.27253#011validation-logloss:0.29094\u001b[0m\n",
      "\u001b[34m[46]#011train-logloss:0.27240#011validation-logloss:0.29085\u001b[0m\n",
      "\u001b[34m[47]#011train-logloss:0.27223#011validation-logloss:0.29084\u001b[0m\n",
      "\u001b[34m[48]#011train-logloss:0.27210#011validation-logloss:0.29078\u001b[0m\n",
      "\u001b[34m[49]#011train-logloss:0.27198#011validation-logloss:0.29069\u001b[0m\n",
      "\n",
      "2023-07-17 14:58:36 Completed - Training job completed\n",
      "Training seconds: 87\n",
      "Billable seconds: 30\n",
      "Managed Spot Training savings: 65.5%\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': s3_input_train,'validation': s3_input_test})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Machine Learning Model As Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2023-07-17-14-59-10-244\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-xgboost-2023-07-17-14-59-10-244\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2023-07-17-14-59-10-244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction of the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9017/2374047114.py:14: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n"
     ]
    }
   ],
   "source": [
    "# from sagemaker.predictor import csv_serializer\n",
    "# from sagemaker.serializers import csv_serializer\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "\n",
    "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #load the data into an array\n",
    "xgb_predictor.content_type = 'text/csv' # set the data type for an inference\n",
    "csv_serializer = CSVSerializer()\n",
    "\n",
    "xgb_predictor.serializer = csv_serializer # set the serializer type\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "\n",
    "\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05214286])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
    "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]; p = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
    "print(\"Observed\")\n",
    "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
    "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting The Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-xgboost-2023-07-17-14-59-10-244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': '1Z4HY5XG9VG1NSCW',\n",
       "   'HostId': 'f9ZtZ46chzklmU18h3xAjEu7lSbsQ0U1YGU+lGh3DXYjLQ2pnQqNyTGrNshYM3lYN/E3a+1oEMM=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'f9ZtZ46chzklmU18h3xAjEu7lSbsQ0U1YGU+lGh3DXYjLQ2pnQqNyTGrNshYM3lYN/E3a+1oEMM=',\n",
       "    'x-amz-request-id': '1Z4HY5XG9VG1NSCW',\n",
       "    'date': 'Mon, 17 Jul 2023 15:07:36 GMT',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3',\n",
       "    'connection': 'close'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/debug-output/index/000000000/000000000000_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/train/train.csv'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/profiler-output/system/incremental/2023071714/1689605820.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/profiler-output/system/incremental/2023071714/1689605880.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/debug-output/index/000000000/000000000040_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/test/test.csv'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/debug-output/events/000000000010/000000000010_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/debug-output/events/000000000020/000000000020_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/debug-output/index/000000000/000000000030_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/debug-output/index/000000000/000000000020_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/debug-output/events/000000000000/000000000000_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/debug-output/collections/000000000/worker_0_collections.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/output/model.tar.gz'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/debug-output/events/000000000030/000000000030_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/debug-output/events/000000000040/000000000040_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/debug-output/claim.smd'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2023-07-17-14-55-27-085/debug-output/index/000000000/000000000010_worker_0.json'}]}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
